{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Cheatbook\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Different ways of creating a DataFrame\n",
    "\n",
    "- `pd.DataFrame(name)` = where name refers to ...\n",
    "    - dictionary: specify key-value pairs\n",
    "    - tuple list: specify the column names in the DataFrame parentheses as `columns=[]`\n",
    "- `pd.read_csv(file_path)` = reading from a csv file\n",
    "- `pd.read_excel(file_path, sheet_name)` = reading from an excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Reading the Data\n",
    "\n",
    "- *`pd.read_csv` parameters...*\n",
    "    - `skiprows=<num_of_rows>` OR `header=<index_row_num>`: for skipping invalid headers in the original csv file\n",
    "    - `header=None` and `names=['column1', 'column2','column3']`: in case of non-existent headers\n",
    "    - `nrows=<num_of_rows>`: restricting a large dataframe to a certain number of rows\n",
    "    - `na_values=['N/A', 'Not available']`: replace the following with `NaN` to correctly label the incomplete values. for column-specific replacement pass a dictionary with keys as column names, and corresponding values as a list of words to be replaced\n",
    "    - `parse_dates=[column_name]`: convert the column that has date values as strings to timestamps\n",
    "\n",
    "- *`pd.read_excel` parameters...*\n",
    "    - `converters = {'column_name': function}`: define a function that takes in a single cell as an argument and returns a different name/value once that condition is satisfied\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# reading the data from the csv file into a variable\n",
    "file_name = \"nyc_weather_data.csv\"\n",
    "df = pd.read_csv(file_name, parse_dates=['EST'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Writing to a CSV file\n",
    "\n",
    "- *`dataframe.to_csv()` parameters...*\n",
    "    - `\"<file_name>.csv\"`\n",
    "    - `index=False`: removes the self-computed index column (visible on terminal)\n",
    "    - `columns=[column1, column2]`: export only the specified columns in the new csv file\n",
    "    - `header=False`: removes the header in the exported csv\n",
    "\n",
    "- *`dataframe.to_excel()` parameters...*\n",
    "    - `\"<file_name>.xlsx\"`\n",
    "    - `sheet_name=\"<sheet_name>\"`\n",
    "    - `startrow=<row_num>`, `startcol=<col_num>`: offset table at row_num and col_num\n",
    "\n",
    "- Write individual dataframes to a single excel file using...\n",
    "```\n",
    "with pd.ExcelWriter('filename.xlsx') as writer:\n",
    "    df_1.to_excel(writer, sheet_name=\"sheet1\")\n",
    "    df_2.to_excel(writer, sheet_name=\"sheet2\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subset of the dataframe and export it to a new csv file\n",
    "df_10rows = pd.read_csv(file_name, nrows=10)\n",
    "df_10rows.to_csv('nyc_weather_data_10rows.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### DataFrame Structure (Rows and Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['EST', 'Temperature', 'DewPoint', 'Humidity', 'Sea Level PressureIn',\n",
       "       'VisibilityMiles', 'WindSpeedMPH', 'PrecipitationIn', 'CloudCover',\n",
       "       'Events', 'WindDirDegrees'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape (i.e. number of rows and columns)\n",
    "print(df.shape)\n",
    "# Output: (rows, columns)\n",
    "\n",
    "# prints all the columns in the dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EST</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>DewPoint</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Sea Level PressureIn</th>\n",
       "      <th>VisibilityMiles</th>\n",
       "      <th>WindSpeedMPH</th>\n",
       "      <th>PrecipitationIn</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>Events</th>\n",
       "      <th>WindDirDegrees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016-01-27</td>\n",
       "      <td>41</td>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>30.03</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>Rain</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "      <td>51</td>\n",
       "      <td>29.90</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-01-29</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>29.58</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016-01-30</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>46</td>\n",
       "      <td>30.01</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>46</td>\n",
       "      <td>28</td>\n",
       "      <td>52</td>\n",
       "      <td>29.90</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          EST  Temperature  DewPoint  Humidity  Sea Level PressureIn  \\\n",
       "26 2016-01-27           41        22        45                 30.03   \n",
       "27 2016-01-28           37        20        51                 29.90   \n",
       "28 2016-01-29           36        21        50                 29.58   \n",
       "29 2016-01-30           34        16        46                 30.01   \n",
       "30 2016-01-31           46        28        52                 29.90   \n",
       "\n",
       "    VisibilityMiles  WindSpeedMPH PrecipitationIn  CloudCover Events  \\\n",
       "26               10           7.0               T           3   Rain   \n",
       "27               10           5.0               0           1    NaN   \n",
       "28               10           8.0               0           4    NaN   \n",
       "29               10           7.0               0           0    NaN   \n",
       "30               10           5.0               0           0    NaN   \n",
       "\n",
       "    WindDirDegrees  \n",
       "26             311  \n",
       "27             234  \n",
       "28             298  \n",
       "29             257  \n",
       "30             241  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # prints the first 5 rows of data\n",
    "df.tail() # prints the last 5 rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints all entries in a specific column\n",
    "df.EST #or df['EST'] --> use this when the column name has spaces\n",
    "\n",
    "# print all entries in multiple specified columns\n",
    "df[['EST','Temperature','DewPoint']]\n",
    "\n",
    "# returns the type of the object\n",
    "type(df.EST) # all pandas columns are in series type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Selecting rows and columns from a Dataframe (The Proper (Explicit) Way !)\n",
    "\n",
    "- `dataframe.loc[row_index,column_name]` is used for filtering rows (**by the row index**) and columns (**by the column name**). It is inclusive of both, first and last numbers\n",
    "\n",
    "- `dataframe.iloc[row_index,column_index]` is used for filtering rows and columns by **integer position**. `iloc` is inclusive of the first, but exclusive of the last index\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EST</th>\n",
       "      <th>DewPoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    EST  DewPoint\n",
       "0  True      True\n",
       "2  True      True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#---------------  .loc ---------------\n",
    "# first row and all columns\n",
    "df.loc[0,:]\n",
    "\n",
    "# first 3 rows and first 3 columns\n",
    "df.loc[0:2,'EST':'DewPoint']\n",
    "\n",
    "# first and third row, first and third column\n",
    "df.loc[[0,2],['EST','DewPoint']]\n",
    "\n",
    "#---------------  .iloc ---------------\n",
    "# first row and all columns\n",
    "df.iloc[0,:]\n",
    "\n",
    "# first 3 rows and first 3 columns\n",
    "df.iloc[0:3, 0:3]\n",
    "\n",
    "# first and third row, first and third column\n",
    "df.iloc[[0,2],[0,2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Basic Stats about a Dataframe\n",
    "\n",
    "- `dataframe[column_name].max()` = returns the maximum value of the series\n",
    "- `dataframe[column_name].min()` = returns the minimum value of the series\n",
    "- `dataframe[column_name].mean()` = returns the mean value of the series\n",
    "\n",
    "- `dataframe.describe()`= returns the count, mean, standard deviation, quartiles, min and max value of all the numerical data (grouped by column_name) in the data frame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>DewPoint</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Sea Level PressureIn</th>\n",
       "      <th>VisibilityMiles</th>\n",
       "      <th>WindSpeedMPH</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>WindDirDegrees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34.677419</td>\n",
       "      <td>17.838710</td>\n",
       "      <td>51.677419</td>\n",
       "      <td>29.992903</td>\n",
       "      <td>9.193548</td>\n",
       "      <td>6.892857</td>\n",
       "      <td>3.129032</td>\n",
       "      <td>247.129032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.639315</td>\n",
       "      <td>11.378626</td>\n",
       "      <td>11.634395</td>\n",
       "      <td>0.237237</td>\n",
       "      <td>1.939405</td>\n",
       "      <td>2.871821</td>\n",
       "      <td>2.629853</td>\n",
       "      <td>92.308086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>29.520000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>29.855000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>238.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.010000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>281.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.500000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>30.140000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>30.570000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>345.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Temperature   DewPoint   Humidity  Sea Level PressureIn  \\\n",
       "count    31.000000  31.000000  31.000000             31.000000   \n",
       "mean     34.677419  17.838710  51.677419             29.992903   \n",
       "std       7.639315  11.378626  11.634395              0.237237   \n",
       "min      20.000000  -3.000000  33.000000             29.520000   \n",
       "25%      29.000000  10.000000  44.500000             29.855000   \n",
       "50%      35.000000  18.000000  50.000000             30.010000   \n",
       "75%      39.500000  23.000000  55.000000             30.140000   \n",
       "max      50.000000  46.000000  78.000000             30.570000   \n",
       "\n",
       "       VisibilityMiles  WindSpeedMPH  CloudCover  WindDirDegrees  \n",
       "count        31.000000     28.000000   31.000000       31.000000  \n",
       "mean          9.193548      6.892857    3.129032      247.129032  \n",
       "std           1.939405      2.871821    2.629853       92.308086  \n",
       "min           1.000000      2.000000    0.000000       34.000000  \n",
       "25%           9.000000      5.000000    1.000000      238.000000  \n",
       "50%          10.000000      6.500000    3.000000      281.000000  \n",
       "75%          10.000000      8.000000    4.500000      300.000000  \n",
       "max          10.000000     16.000000    8.000000      345.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Conditional Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>DewPoint</th>\n",
       "      <th>WindSpeedMPH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  DewPoint  WindSpeedMPH\n",
       "6           39        11           2.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print all the rows where the temperature is greater than 34\n",
    "df[df['Temperature'] >= 34]\n",
    "\n",
    "# print all the rows where the dew point is maximum\n",
    "df[df['DewPoint'] == df['DewPoint'].max()]\n",
    "\n",
    "# print only the temp, dew and windspeed when humidity is least\n",
    "df[['Temperature', 'DewPoint','WindSpeedMPH']][df['Humidity']==df['Humidity'].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Indexing a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using one of the columns as an index\n",
    "df_ESTindex = df.set_index('EST')\n",
    "# you can also modify the original dataframe by: df.set_index('EST', inplace=True)\n",
    "\n",
    "# returns the row where the date (i.e. EST) = '1/5/2016'\n",
    "df_ESTindex.loc['1/5/2016'] \n",
    "# type = pd.series\n",
    "\n",
    "# resetting the index to the original one\n",
    "df_ESTindex.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Handling Missing Values\n",
    "\n",
    "- *`dataframe.fillna(value)` parameters ...*\n",
    "    - `value`: replaces 'NaN' with the specified value. Doesn't change the original dataframe unless `inplace=True` is specified. Pass a dictionary with key as column name and value as replacement word/number to fill comlumn-specific NaN values\n",
    "\n",
    "    - `method=\"ffill\"` OR `method=\"bfill\"`: fills the value from the previous rows OR the next row (by default)\n",
    "\n",
    "    - `axis='rows'` OR `axis='columns'`: fills the value from the rows OR columns\n",
    "\n",
    "    - `limit=<num>`: carryforwards the value only a certain number of times\n",
    "\n",
    "- *Use `dataframe.interpolate()` for filling in numerical data...*\n",
    "    - `method='linear'`: default\n",
    "    - `method='time'`: takes into account the time aspect in relation with the data. For this, the date column needs to be in timestamp formate and set as an index of the dataframe\n",
    "\n",
    "- *Use `dataframe.dropna()` to drop rows that have at least 1 NaN value*\n",
    "    - `how=\"all\"`: drop rows that have all NaN values\n",
    "    - `thresh=<num>`: keep the rows that have at least a certain number of non-NaN values and drop the rest\n",
    "\n",
    "- *`dataframe.replace()`*\n",
    "    - `.replace(value, correct_value)`: replace value/list/dictionary of values with the correct_value/list of correct_value (accordingly)\n",
    "    OR\n",
    "    - use a dictionary to map out incorrect data (as keys) with correct data (as values)\n",
    "    - use regex to detect patterns and replace data accordingly.\n",
    "    ```\n",
    "    df.replace({\n",
    "        'column1': '[A-Za-z]'\n",
    "    }, '', regex=True)\n",
    "    # replaces any text(upper or lower) with a blank space\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN with 'No Event' in 'Events' column\n",
    "df_replaceNaN = df.fillna({\n",
    "    'Events':'No Event'\n",
    "})\n",
    "\n",
    "# fills the current row with the next row's value\n",
    "df_rainbfill = df.fillna(method=\"bfill\", limit=1, axis='rows')\n",
    "\n",
    "# drop all rows that have atleast 1 NaN value\n",
    "df_dropNA = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Group By (Split Apply Combine - Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fog-Snow\n",
      "          EST  Temperature  DewPoint  Humidity  Sea Level PressureIn  \\\n",
      "16 2016-01-17           36        23        66                 29.78   \n",
      "22 2016-01-23           26        21        78                 29.77   \n",
      "\n",
      "    VisibilityMiles  WindSpeedMPH PrecipitationIn  CloudCover    Events  \\\n",
      "16                8           6.0            0.05           6  Fog-Snow   \n",
      "22                1          16.0            2.31           8  Fog-Snow   \n",
      "\n",
      "    WindDirDegrees  \n",
      "16             345  \n",
      "22              42  \n",
      "Rain\n",
      "          EST  Temperature  DewPoint  Humidity  Sea Level PressureIn  \\\n",
      "8  2016-01-09           44        38        77                 30.16   \n",
      "9  2016-01-10           50        46        71                 29.59   \n",
      "15 2016-01-16           47        37        70                 29.52   \n",
      "26 2016-01-27           41        22        45                 30.03   \n",
      "\n",
      "    VisibilityMiles  WindSpeedMPH PrecipitationIn  CloudCover Events  \\\n",
      "8                 9           8.0               T           8   Rain   \n",
      "9                 4           NaN             1.8           7   Rain   \n",
      "15                8           7.0            0.24           7   Rain   \n",
      "26               10           7.0               T           3   Rain   \n",
      "\n",
      "    WindDirDegrees  \n",
      "8               76  \n",
      "9              109  \n",
      "15             340  \n",
      "26             311  \n",
      "Snow\n",
      "          EST  Temperature  DewPoint  Humidity  Sea Level PressureIn  \\\n",
      "17 2016-01-18           25         6        53                 29.83   \n",
      "21 2016-01-22           26         6        41                 30.21   \n",
      "23 2016-01-24           28        11        53                 29.92   \n",
      "\n",
      "    VisibilityMiles  WindSpeedMPH PrecipitationIn  CloudCover Events  \\\n",
      "17                9          12.0               T           2   Snow   \n",
      "21                9           NaN            0.01           3   Snow   \n",
      "23                8           6.0               T           3   Snow   \n",
      "\n",
      "    WindDirDegrees  \n",
      "17             293  \n",
      "21              34  \n",
      "23             327  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Temperature</th>\n",
       "      <th colspan=\"2\" halign=\"left\">DewPoint</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CloudCover</th>\n",
       "      <th colspan=\"8\" halign=\"left\">WindDirDegrees</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Events</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fog-Snow</th>\n",
       "      <td>2.0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.50</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.50</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>193.5</td>\n",
       "      <td>214.253355</td>\n",
       "      <td>42.0</td>\n",
       "      <td>117.75</td>\n",
       "      <td>193.5</td>\n",
       "      <td>269.25</td>\n",
       "      <td>345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rain</th>\n",
       "      <td>4.0</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>3.872983</td>\n",
       "      <td>41.0</td>\n",
       "      <td>43.25</td>\n",
       "      <td>45.5</td>\n",
       "      <td>47.75</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>135.712932</td>\n",
       "      <td>76.0</td>\n",
       "      <td>100.75</td>\n",
       "      <td>210.0</td>\n",
       "      <td>318.25</td>\n",
       "      <td>340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow</th>\n",
       "      <td>3.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.527525</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.50</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>160.252925</td>\n",
       "      <td>34.0</td>\n",
       "      <td>163.50</td>\n",
       "      <td>293.0</td>\n",
       "      <td>310.00</td>\n",
       "      <td>327.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Temperature                                                       \\\n",
       "               count       mean       std   min    25%   50%    75%   max   \n",
       "Events                                                                      \n",
       "Fog-Snow         2.0  31.000000  7.071068  26.0  28.50  31.0  33.50  36.0   \n",
       "Rain             4.0  45.500000  3.872983  41.0  43.25  45.5  47.75  50.0   \n",
       "Snow             3.0  26.333333  1.527525  25.0  25.50  26.0  27.00  28.0   \n",
       "\n",
       "         DewPoint             ... CloudCover      WindDirDegrees         \\\n",
       "            count       mean  ...        75%  max          count   mean   \n",
       "Events                        ...                                         \n",
       "Fog-Snow      2.0  22.000000  ...       7.50  8.0            2.0  193.5   \n",
       "Rain          4.0  35.750000  ...       7.25  8.0            4.0  209.0   \n",
       "Snow          3.0   7.666667  ...       3.00  3.0            3.0  218.0   \n",
       "\n",
       "                                                          \n",
       "                 std   min     25%    50%     75%    max  \n",
       "Events                                                    \n",
       "Fog-Snow  214.253355  42.0  117.75  193.5  269.25  345.0  \n",
       "Rain      135.712932  76.0  100.75  210.0  318.25  340.0  \n",
       "Snow      160.252925  34.0  163.50  293.0  310.00  327.0  \n",
       "\n",
       "[3 rows x 64 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = df.groupby('Events')\n",
    "# returns 2 values: key (i.e. event) and \n",
    "# a mini-dataframe corresponding to that key (i.e. event_df) \n",
    "\n",
    "for event, event_df in events:\n",
    "    print(event)\n",
    "    print(event_df)\n",
    "\n",
    "# get a specific dataframe relating to a specific group\n",
    "events.get_group('Snow')\n",
    "\n",
    "# to get the basic stats for each group\n",
    "events.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Concatenating Dataframes\n",
    "\n",
    "- *`pd.concat()` parameters...*\n",
    "    - `ignore_index=True`: start index the sequentially for the combined dataframe\n",
    "    - `keys=[]`: to label/differentiate the concatenated dataframes. `ignore_index=False` for this to work\n",
    "    - `axis=0` OR `axis=1`: append 2nd dataframe as rows OR cols\n",
    "\n",
    "- *`pd.merge()` chooses the intersection/common elements from each dataframe and merges it onto a common column. Its parameters are...*\n",
    "    - `dataframe1`, `dataframe2`\n",
    "    - `on=\"<common_column_name>\"`\n",
    "    - `how=\"outer\"`: outer/full join ie. union (`how=\"inner\"` by default; other options include \"left\", \"right\")\n",
    "    - `indicator=True`: adds a column to highlight where the data came from\n",
    "    - `suffixes=(\"_name1\", \"_name2\")`: to add suffixes to columns with the same name but different values in both dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>temp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mumbai</td>\n",
       "      <td>35</td>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bangalore</td>\n",
       "      <td>40</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pune</td>\n",
       "      <td>23</td>\n",
       "      <td>55</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        city  temp  humidity  windspeed\n",
       "0     mumbai    35        53         20\n",
       "1  bangalore    40        60         10\n",
       "2       pune    23        55         40"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_df_1 = pd.DataFrame({\n",
    "    \"city\": [\"mumbai\",\"bangalore\",\"pune\"],\n",
    "    \"temp\": [35,40,23],\n",
    "    \"humidity\": [53,60,55]\n",
    "})\n",
    "\n",
    "small_df_2 = pd.DataFrame({\n",
    "    \"city\":[\"london\",\"ramsgate\",\"manchester\"],\n",
    "    \"temp\": [10,20,15],\n",
    "    \"humidity\": [30,57,40]\n",
    "\n",
    "})\n",
    "\n",
    "small_df = pd.concat([small_df_1, small_df_2],\n",
    "                    keys=[\"india\",\"uk\"], axis=0)\n",
    "\n",
    "# print the specific dataframe using the key\n",
    "small_df.loc['india']\n",
    "\n",
    "# append a series\n",
    "series_india = pd.Series([20,10,40],name='windspeed')\n",
    "small_df_1 = pd.concat([small_df_1,series_india], axis=1)\n",
    "small_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>humidity</th>\n",
       "      <th>temp</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mumbai</td>\n",
       "      <td>53.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bangalore</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pune</td>\n",
       "      <td>55.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ramsgate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        city  humidity  temp      _merge\n",
       "0     mumbai      53.0  10.0        both\n",
       "1  bangalore      60.0   NaN   left_only\n",
       "2       pune      55.0  20.0        both\n",
       "3   ramsgate       NaN  15.0  right_only"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_df_3 = pd.DataFrame({\n",
    "    \"city\": [\"mumbai\",\"bangalore\",\"pune\"],\n",
    "    \"humidity\": [53,60,55]\n",
    "})\n",
    "\n",
    "small_df_4 = pd.DataFrame({\n",
    "    \"city\":[\"mumbai\",\"pune\",\"ramsgate\"],\n",
    "    \"temp\": [10,20,15]\n",
    "\n",
    "})\n",
    "\n",
    "# inner join\n",
    "small_df_5 = pd.merge(small_df_3, small_df_4, on='city')\n",
    "\n",
    "# outer join\n",
    "small_df_6 = pd.merge(small_df_3, small_df_4, on='city', how=\"outer\", indicator=True)\n",
    "small_df_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Pivots and Pivot Tables\n",
    "\n",
    "**Pivot**: Transforms/reshapes data\n",
    "**Pivot Table**: Summarises and aggregates data inside dataframe\n",
    "\n",
    "- *`dataframe.pivot()` parameters...*\n",
    "    - `index=\"<column_name1>\"`: the row index\n",
    "    - `columns=\"<column_name2>\"`: the column index\n",
    "    - `values=\"<column_name3>\"`: (optional) if there's only a specific column to be outputted\n",
    "\n",
    "- *`dataframe.pivot_table()` parameters...*\n",
    "    - `index=\"<column_name1>\"`: the row index \n",
    "    OR can use `index = pd.grouper(freq=\"M\",key=\"date_column\")` to group by month <-- [`date_column` must be in datetime format]\n",
    "    - `columns=\"<column_name2>\"`: the column index\n",
    "    - `aggfunc=\"mean\"` OR `aggfunc=\"sum\"` : values aggregated using mean or sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Events</th>\n",
       "      <th>NaN</th>\n",
       "      <th>Fog-Snow</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Snow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EST</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-13</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-14</th>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-15</th>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-19</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-20</th>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-21</th>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-25</th>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-26</th>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-28</th>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-29</th>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-30</th>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-31</th>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Events       NaN  Fog-Snow  Rain  Snow\n",
       "EST                                   \n",
       "2016-01-01  23.0       NaN   NaN   NaN\n",
       "2016-01-02  18.0       NaN   NaN   NaN\n",
       "2016-01-03  21.0       NaN   NaN   NaN\n",
       "2016-01-04   9.0       NaN   NaN   NaN\n",
       "2016-01-05  -3.0       NaN   NaN   NaN\n",
       "2016-01-06   4.0       NaN   NaN   NaN\n",
       "2016-01-07  11.0       NaN   NaN   NaN\n",
       "2016-01-08  29.0       NaN   NaN   NaN\n",
       "2016-01-09   NaN       NaN  38.0   NaN\n",
       "2016-01-10   NaN       NaN  46.0   NaN\n",
       "2016-01-11   8.0       NaN   NaN   NaN\n",
       "2016-01-12  15.0       NaN   NaN   NaN\n",
       "2016-01-13   4.0       NaN   NaN   NaN\n",
       "2016-01-14  12.0       NaN   NaN   NaN\n",
       "2016-01-15  31.0       NaN   NaN   NaN\n",
       "2016-01-16   NaN       NaN  37.0   NaN\n",
       "2016-01-17   NaN      23.0   NaN   NaN\n",
       "2016-01-18   NaN       NaN   NaN   6.0\n",
       "2016-01-19   3.0       NaN   NaN   NaN\n",
       "2016-01-20  15.0       NaN   NaN   NaN\n",
       "2016-01-21  11.0       NaN   NaN   NaN\n",
       "2016-01-22   NaN       NaN   NaN   6.0\n",
       "2016-01-23   NaN      21.0   NaN   NaN\n",
       "2016-01-24   NaN       NaN   NaN  11.0\n",
       "2016-01-25  18.0       NaN   NaN   NaN\n",
       "2016-01-26  29.0       NaN   NaN   NaN\n",
       "2016-01-27   NaN       NaN  22.0   NaN\n",
       "2016-01-28  20.0       NaN   NaN   NaN\n",
       "2016-01-29  21.0       NaN   NaN   NaN\n",
       "2016-01-30  16.0       NaN   NaN   NaN\n",
       "2016-01-31  28.0       NaN   NaN   NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot(index=\"EST\", columns=\"Events\",  values=\"DewPoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>humidity</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mumbai</th>\n",
       "      <td>60.666667</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>57.666667</td>\n",
       "      <td>65.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>59.166667</td>\n",
       "      <td>70.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           humidity       temp\n",
       "city                          \n",
       "mumbai    60.666667  75.000000\n",
       "new york  57.666667  65.333333\n",
       "All       59.166667  70.166667"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = pd.DataFrame({\n",
    "    \"city\":[\"new york\", \"new york\", \"new york\", \"mumbai\", \"mumbai\", \"mumbai\"],\n",
    "    \"temp\":[65,61,70,72,75,78],\n",
    "    \"humidity\": [56,57,60,82,45,55]\n",
    "})\n",
    "\n",
    "df_2.pivot_table(index=\"city\",aggfunc=\"mean\",margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Stack and Unstack\n",
    "\n",
    "Useful for data with multiple headers\n",
    "\n",
    "*`dataframe.stack()` parameters...*\n",
    "- `level=<num>`: define the header index upon which the data is to be stacked\n",
    "\n",
    "*`stacked_dataframe.unstack()`* = to get original dataframe back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Price</th>\n",
       "      <th colspan=\"3\" halign=\"left\">P/E</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>Google</th>\n",
       "      <th>Microsoft</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>Google</th>\n",
       "      <th>Microsoft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-05-06</th>\n",
       "      <td>155</td>\n",
       "      <td>955</td>\n",
       "      <td>68</td>\n",
       "      <td>34.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>29.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-06</th>\n",
       "      <td>150</td>\n",
       "      <td>925</td>\n",
       "      <td>75</td>\n",
       "      <td>40.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-06</th>\n",
       "      <td>160</td>\n",
       "      <td>930</td>\n",
       "      <td>60</td>\n",
       "      <td>39.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-06</th>\n",
       "      <td>162</td>\n",
       "      <td>934</td>\n",
       "      <td>55</td>\n",
       "      <td>41.0</td>\n",
       "      <td>38.9</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-06</th>\n",
       "      <td>149</td>\n",
       "      <td>921</td>\n",
       "      <td>59</td>\n",
       "      <td>35.8</td>\n",
       "      <td>39.5</td>\n",
       "      <td>35.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Price                       P/E                 \n",
       "Company    Facebook Google Microsoft Facebook Google Microsoft\n",
       "2017-05-06      155    955        68     34.5   36.0      29.8\n",
       "2017-06-06      150    925        75     40.1   37.8      30.0\n",
       "2017-07-06      160    930        60     39.5   40.0      31.0\n",
       "2017-08-06      162    934        55     41.0   38.9      32.7\n",
       "2017-09-06      149    921        59     35.8   39.5      35.6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"stocks.xlsx\"\n",
    "\n",
    "stocks_df = pd.read_excel(file_name, header=[0,1], index_col=0)\n",
    "stocks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>P/E</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2017-05-06</th>\n",
       "      <th>Facebook</th>\n",
       "      <td>34.5</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>36.0</td>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Microsoft</th>\n",
       "      <td>29.8</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2017-06-06</th>\n",
       "      <th>Facebook</th>\n",
       "      <td>40.1</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>37.8</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Microsoft</th>\n",
       "      <td>30.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2017-07-06</th>\n",
       "      <th>Facebook</th>\n",
       "      <td>39.5</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>40.0</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Microsoft</th>\n",
       "      <td>31.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2017-08-06</th>\n",
       "      <th>Facebook</th>\n",
       "      <td>41.0</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>38.9</td>\n",
       "      <td>934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Microsoft</th>\n",
       "      <td>32.7</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2017-09-06</th>\n",
       "      <th>Facebook</th>\n",
       "      <td>35.8</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>39.5</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Microsoft</th>\n",
       "      <td>35.6</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       P/E  Price\n",
       "           Company               \n",
       "2017-05-06 Facebook   34.5    155\n",
       "           Google     36.0    955\n",
       "           Microsoft  29.8     68\n",
       "2017-06-06 Facebook   40.1    150\n",
       "           Google     37.8    925\n",
       "           Microsoft  30.0     75\n",
       "2017-07-06 Facebook   39.5    160\n",
       "           Google     40.0    930\n",
       "           Microsoft  31.0     60\n",
       "2017-08-06 Facebook   41.0    162\n",
       "           Google     38.9    934\n",
       "           Microsoft  32.7     55\n",
       "2017-09-06 Facebook   35.8    149\n",
       "           Google     39.5    921\n",
       "           Microsoft  35.6     59"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_df.stack(level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Cross Tabs/Contingency Tables\n",
    "\n",
    "**Contingency Table**: Type of table in a matrix format that displays the frequency distribution of the variables\n",
    "\n",
    "*`pd.crosstab()` parameters...*\n",
    "- `dataframe.column1`, `dataframe.column2` (can also supply 2 or more columns to provide multi-header crosstabs)\n",
    "- `margins=True`: gives the total of the crosstab\n",
    "- `normalize=\"index\"` OR `normalize=\"columns\"`: returns the percentage (i.e. value/sum of values)\n",
    "- `values=dataframe[column_name]` : (optional) Values to aggregate on as specified by `aggfunc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Nationality', 'Sex', 'Age', 'Handedness'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"survey.csv\"\n",
    "\n",
    "survey_df = pd.read_csv(file_name)\n",
    "survey_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Handedness</th>\n",
       "      <th>Left</th>\n",
       "      <th>Right</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Handedness      Left     Right\n",
       "Sex                           \n",
       "Female      0.400000  0.600000\n",
       "Male        0.714286  0.285714"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(survey_df[\"Sex\"],survey_df[\"Handedness\"], normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Handedness</th>\n",
       "      <th>Left</th>\n",
       "      <th>Right</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>44.5</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>31.2</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Handedness  Left  Right\n",
       "Sex                    \n",
       "Female      44.5   31.0\n",
       "Male        31.2   28.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# gives the mean age of Males & Females, who are right/left handed\n",
    "pd.crosstab(survey_df[\"Sex\"],survey_df[\"Handedness\"], values=survey_df.Age, aggfunc=np.average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Memory Optimisation Tips\n",
    "\n",
    "Ref: (https://pythonspeed.com/articles/pandas-load-less-data/)\n",
    "\n",
    "- `dataframe.info(verbose=False, memory_usage=\"deep\")`: returns the memory used when importing the dataframe\n",
    "\n",
    "- `dataframe = pd.read_csv(filename, usecols=['col1','col2'])`: returns only specific columns from the file, instead of importing the whole dataset\n",
    "\n",
    "- `dataframe = dataframe[['col1','col2']]`: works in a similar way to `usecols`\n",
    "\n",
    "- `dataframe = pd.read_csv(filename, dtype={'col1':'int8'})`: specifies dtype for integers (eg: int8 takes -127 to 128)\n",
    "\n",
    "...and more such tips in the ref article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Time Series: DateTime Functions\n",
    "\n",
    "**Time Series Data**: Data points indexed in Time order. Datetime index is useful for slicing a subset based on date and directly referencing a row based on date\n",
    "\n",
    "- *`dataframe.column_name.resample(\"W\").mean()`*: Resamples the data into that particular column, in a weekly time frame (other options: \"M\" = monthly, \"D\" = daily, \"Q\" = quarterly)\n",
    "\n",
    "- *`pd.date_range()`*: provides dates to a data set as a column. Parameters...\n",
    "    - `start=\"start_date\"`, `end=\"end_date\"`\n",
    "    - `freq='B'`: only count business days\n",
    "Then use `dataframe.set_index(dates, inplace=True)` to re-date the dataframe\n",
    "\n",
    "- *`pd.to_datetime()`* is a powerful tool that converts any of the following `['2017-01-05', 'Jan 5, 2017', '01/05/2017', '2017.01.05', '2017/01/05', '20170105']` to `'2017-01-05'`\n",
    "    \n",
    "    - For converting to European date style i.e. yyyy/mm/dd use `pd.to_datetime('5/1/2017', dayfirst=True)` OR specify the exact format using `pd.to_datetime('5/1/2017', format='%d/%m/%Y')`\n",
    "    \n",
    "    - For invalid date inputs, pass the following parameters in `pd.to_datetime()`:\n",
    "        - *`errors=\"ignore\"`*\n",
    "        - *`errors=\"coerce\"`*: to convert to 'NaT'\n",
    "    \n",
    "    - To convert from epoch to normal datetime use `normal_datetime = pd.to_datetime(epoch_time, unit='s')`. To convert back to epoch time, use `normal_datetime.view('int64')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>177.83</td>\n",
       "      <td>182.88</td>\n",
       "      <td>177.71</td>\n",
       "      <td>182.01</td>\n",
       "      <td>104701220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>182.63</td>\n",
       "      <td>182.94</td>\n",
       "      <td>179.12</td>\n",
       "      <td>179.70</td>\n",
       "      <td>99310438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>179.61</td>\n",
       "      <td>180.17</td>\n",
       "      <td>174.64</td>\n",
       "      <td>174.92</td>\n",
       "      <td>94537602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>172.70</td>\n",
       "      <td>175.30</td>\n",
       "      <td>171.64</td>\n",
       "      <td>172.00</td>\n",
       "      <td>96903955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>172.89</td>\n",
       "      <td>174.14</td>\n",
       "      <td>171.03</td>\n",
       "      <td>172.17</td>\n",
       "      <td>86709147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-10</th>\n",
       "      <td>169.08</td>\n",
       "      <td>172.50</td>\n",
       "      <td>168.17</td>\n",
       "      <td>172.19</td>\n",
       "      <td>106765552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>172.32</td>\n",
       "      <td>175.18</td>\n",
       "      <td>170.82</td>\n",
       "      <td>175.08</td>\n",
       "      <td>76138312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-12</th>\n",
       "      <td>176.12</td>\n",
       "      <td>177.18</td>\n",
       "      <td>174.82</td>\n",
       "      <td>175.53</td>\n",
       "      <td>74805173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-13</th>\n",
       "      <td>175.78</td>\n",
       "      <td>176.62</td>\n",
       "      <td>171.79</td>\n",
       "      <td>172.19</td>\n",
       "      <td>84505760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14</th>\n",
       "      <td>171.34</td>\n",
       "      <td>173.78</td>\n",
       "      <td>171.09</td>\n",
       "      <td>173.07</td>\n",
       "      <td>80440780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-18</th>\n",
       "      <td>171.51</td>\n",
       "      <td>172.54</td>\n",
       "      <td>169.41</td>\n",
       "      <td>169.80</td>\n",
       "      <td>91168729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-19</th>\n",
       "      <td>170.00</td>\n",
       "      <td>171.08</td>\n",
       "      <td>165.94</td>\n",
       "      <td>166.23</td>\n",
       "      <td>94814990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-20</th>\n",
       "      <td>166.98</td>\n",
       "      <td>169.68</td>\n",
       "      <td>164.18</td>\n",
       "      <td>164.51</td>\n",
       "      <td>91420515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-21</th>\n",
       "      <td>164.42</td>\n",
       "      <td>166.33</td>\n",
       "      <td>162.30</td>\n",
       "      <td>162.41</td>\n",
       "      <td>122848858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-24</th>\n",
       "      <td>160.02</td>\n",
       "      <td>162.30</td>\n",
       "      <td>154.70</td>\n",
       "      <td>161.62</td>\n",
       "      <td>162706686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-25</th>\n",
       "      <td>158.98</td>\n",
       "      <td>162.76</td>\n",
       "      <td>157.02</td>\n",
       "      <td>159.78</td>\n",
       "      <td>115798367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-26</th>\n",
       "      <td>163.50</td>\n",
       "      <td>164.39</td>\n",
       "      <td>157.82</td>\n",
       "      <td>159.69</td>\n",
       "      <td>108275308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-27</th>\n",
       "      <td>162.45</td>\n",
       "      <td>163.84</td>\n",
       "      <td>158.28</td>\n",
       "      <td>159.22</td>\n",
       "      <td>121954638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-28</th>\n",
       "      <td>165.71</td>\n",
       "      <td>170.35</td>\n",
       "      <td>162.80</td>\n",
       "      <td>170.33</td>\n",
       "      <td>179935660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close     Volume\n",
       "Date                                                 \n",
       "2022-01-03  177.83  182.88  177.71  182.01  104701220\n",
       "2022-01-04  182.63  182.94  179.12  179.70   99310438\n",
       "2022-01-05  179.61  180.17  174.64  174.92   94537602\n",
       "2022-01-06  172.70  175.30  171.64  172.00   96903955\n",
       "2022-01-07  172.89  174.14  171.03  172.17   86709147\n",
       "2022-01-10  169.08  172.50  168.17  172.19  106765552\n",
       "2022-01-11  172.32  175.18  170.82  175.08   76138312\n",
       "2022-01-12  176.12  177.18  174.82  175.53   74805173\n",
       "2022-01-13  175.78  176.62  171.79  172.19   84505760\n",
       "2022-01-14  171.34  173.78  171.09  173.07   80440780\n",
       "2022-01-18  171.51  172.54  169.41  169.80   91168729\n",
       "2022-01-19  170.00  171.08  165.94  166.23   94814990\n",
       "2022-01-20  166.98  169.68  164.18  164.51   91420515\n",
       "2022-01-21  164.42  166.33  162.30  162.41  122848858\n",
       "2022-01-24  160.02  162.30  154.70  161.62  162706686\n",
       "2022-01-25  158.98  162.76  157.02  159.78  115798367\n",
       "2022-01-26  163.50  164.39  157.82  159.69  108275308\n",
       "2022-01-27  162.45  163.84  158.28  159.22  121954638\n",
       "2022-01-28  165.71  170.35  162.80  170.33  179935660"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"apple_Jan2022.csv\"\n",
    "\n",
    "apple_stock_df = pd.read_csv(file_name, header=1, parse_dates=[\"Date\"], index_col=\"Date\")\n",
    "apple_stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2022-01-09    176.1600\n",
       "2022-01-16    173.6120\n",
       "2022-01-23    165.7375\n",
       "2022-01-30    162.1280\n",
       "Freq: W-SUN, Name: Close, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns the average stock closing price per week\n",
    "apple_stock_df.Close.resample('W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_stock_df_no_date = apple_stock_df.reset_index().drop(\"Date\", axis=1)\n",
    "\n",
    "apple_date_range = pd.date_range(start = \"1/1/2022\", end = \"28/1/2022\", freq=\"C\")\n",
    "\n",
    "# remove '2022-01-17'\n",
    "apple_date_range = apple_date_range.delete(apple_date_range.get_loc('2022-01-17'))\n",
    "\n",
    "# set index to the undated dataframe\n",
    "apple_stock_df_no_date.set_index(apple_date_range, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way to remove the 17th Jan holiday would be to use the `USFederalHolidayCalender` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>177.83</td>\n",
       "      <td>182.88</td>\n",
       "      <td>177.71</td>\n",
       "      <td>182.01</td>\n",
       "      <td>104701220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>182.63</td>\n",
       "      <td>182.94</td>\n",
       "      <td>179.12</td>\n",
       "      <td>179.70</td>\n",
       "      <td>99310438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>179.61</td>\n",
       "      <td>180.17</td>\n",
       "      <td>174.64</td>\n",
       "      <td>174.92</td>\n",
       "      <td>94537602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>172.70</td>\n",
       "      <td>175.30</td>\n",
       "      <td>171.64</td>\n",
       "      <td>172.00</td>\n",
       "      <td>96903955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>172.89</td>\n",
       "      <td>174.14</td>\n",
       "      <td>171.03</td>\n",
       "      <td>172.17</td>\n",
       "      <td>86709147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-10</th>\n",
       "      <td>169.08</td>\n",
       "      <td>172.50</td>\n",
       "      <td>168.17</td>\n",
       "      <td>172.19</td>\n",
       "      <td>106765552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>172.32</td>\n",
       "      <td>175.18</td>\n",
       "      <td>170.82</td>\n",
       "      <td>175.08</td>\n",
       "      <td>76138312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-12</th>\n",
       "      <td>176.12</td>\n",
       "      <td>177.18</td>\n",
       "      <td>174.82</td>\n",
       "      <td>175.53</td>\n",
       "      <td>74805173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-13</th>\n",
       "      <td>175.78</td>\n",
       "      <td>176.62</td>\n",
       "      <td>171.79</td>\n",
       "      <td>172.19</td>\n",
       "      <td>84505760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14</th>\n",
       "      <td>171.34</td>\n",
       "      <td>173.78</td>\n",
       "      <td>171.09</td>\n",
       "      <td>173.07</td>\n",
       "      <td>80440780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-18</th>\n",
       "      <td>171.51</td>\n",
       "      <td>172.54</td>\n",
       "      <td>169.41</td>\n",
       "      <td>169.80</td>\n",
       "      <td>91168729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-19</th>\n",
       "      <td>170.00</td>\n",
       "      <td>171.08</td>\n",
       "      <td>165.94</td>\n",
       "      <td>166.23</td>\n",
       "      <td>94814990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-20</th>\n",
       "      <td>166.98</td>\n",
       "      <td>169.68</td>\n",
       "      <td>164.18</td>\n",
       "      <td>164.51</td>\n",
       "      <td>91420515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-21</th>\n",
       "      <td>164.42</td>\n",
       "      <td>166.33</td>\n",
       "      <td>162.30</td>\n",
       "      <td>162.41</td>\n",
       "      <td>122848858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-24</th>\n",
       "      <td>160.02</td>\n",
       "      <td>162.30</td>\n",
       "      <td>154.70</td>\n",
       "      <td>161.62</td>\n",
       "      <td>162706686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-25</th>\n",
       "      <td>158.98</td>\n",
       "      <td>162.76</td>\n",
       "      <td>157.02</td>\n",
       "      <td>159.78</td>\n",
       "      <td>115798367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-26</th>\n",
       "      <td>163.50</td>\n",
       "      <td>164.39</td>\n",
       "      <td>157.82</td>\n",
       "      <td>159.69</td>\n",
       "      <td>108275308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-27</th>\n",
       "      <td>162.45</td>\n",
       "      <td>163.84</td>\n",
       "      <td>158.28</td>\n",
       "      <td>159.22</td>\n",
       "      <td>121954638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-28</th>\n",
       "      <td>165.71</td>\n",
       "      <td>170.35</td>\n",
       "      <td>162.80</td>\n",
       "      <td>170.33</td>\n",
       "      <td>179935660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close     Volume\n",
       "2022-01-03  177.83  182.88  177.71  182.01  104701220\n",
       "2022-01-04  182.63  182.94  179.12  179.70   99310438\n",
       "2022-01-05  179.61  180.17  174.64  174.92   94537602\n",
       "2022-01-06  172.70  175.30  171.64  172.00   96903955\n",
       "2022-01-07  172.89  174.14  171.03  172.17   86709147\n",
       "2022-01-10  169.08  172.50  168.17  172.19  106765552\n",
       "2022-01-11  172.32  175.18  170.82  175.08   76138312\n",
       "2022-01-12  176.12  177.18  174.82  175.53   74805173\n",
       "2022-01-13  175.78  176.62  171.79  172.19   84505760\n",
       "2022-01-14  171.34  173.78  171.09  173.07   80440780\n",
       "2022-01-18  171.51  172.54  169.41  169.80   91168729\n",
       "2022-01-19  170.00  171.08  165.94  166.23   94814990\n",
       "2022-01-20  166.98  169.68  164.18  164.51   91420515\n",
       "2022-01-21  164.42  166.33  162.30  162.41  122848858\n",
       "2022-01-24  160.02  162.30  154.70  161.62  162706686\n",
       "2022-01-25  158.98  162.76  157.02  159.78  115798367\n",
       "2022-01-26  163.50  164.39  157.82  159.69  108275308\n",
       "2022-01-27  162.45  163.84  158.28  159.22  121954638\n",
       "2022-01-28  165.71  170.35  162.80  170.33  179935660"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "\n",
    "usb = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "\n",
    "apple_stock_df_no_date = apple_stock_df.reset_index().drop(\"Date\", axis=1)\n",
    "apple_stock_df_no_date\n",
    "\n",
    "apple_date_range = pd.date_range(start = \"1/1/2022\", end = \"28/1/2022\", freq=usb)\n",
    "apple_date_range\n",
    "\n",
    "# set index to the undated dataframe\n",
    "apple_stock_df_no_date.set_index(apple_date_range, inplace=True)\n",
    "apple_stock_df_no_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-01-05 00:00:00')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('5/1/2017', format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Time Series: Period\n",
    "\n",
    "- Create a annual / month period object using `y = pd.Period('yyyy')` / `m = pd.Period('yyyy-m', freq='M')` <-- other frequencies like day,hour,etc are also available.\n",
    "    - `y.start_time`, `y.end_time` / `m.start_time`, `m.end_time` = gives you the start and end date of the year/month respectively\n",
    "    \n",
    "    - `y+1` / `m+1` to go to the next year / month\n",
    "\n",
    "    - Use `y.asfreq('M',how=\"start\")` to covert a yearly frequecy to monthly frequency (in this eg)\n",
    "\n",
    "- Create a period range using `pd.period_range('<start_year>','<end_year>',freq='M'/'Q')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2022', 'A-DEC')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.Period('2021')\n",
    "y+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a normal Calendar Year...\n",
      "1st Quarter: 2019-01-01 00:00:00 to 2019-03-31 23:59:59.999999999\n",
      "2nd Quarter: 2019-04-01 00:00:00 to 2019-06-30 23:59:59.999999999\n",
      "3rd Quarter: 2019-07-01 00:00:00 to 2019-09-30 23:59:59.999999999\n",
      "4th Quarter: 2019-10-01 00:00:00 to 2019-12-31 23:59:59.999999999\n",
      "\n",
      "For a Fiscal Year...\n",
      "1st Quarter: 2018-04-01 00:00:00 to 2018-06-30 23:59:59.999999999\n",
      "2nd Quarter: 2018-07-01 00:00:00 to 2018-09-30 23:59:59.999999999\n",
      "3rd Quarter: 2018-10-01 00:00:00 to 2018-12-31 23:59:59.999999999\n",
      "4th Quarter: 2019-01-01 00:00:00 to 2019-03-31 23:59:59.999999999\n"
     ]
    }
   ],
   "source": [
    "# creating a quarterly period\n",
    "\n",
    "q = pd.Period('2019Q1') \n",
    "# Output: Period('2019Q1', 'Q-DEC')\n",
    "print(\"For a normal calendar Year...\")\n",
    "print('1st Quarter: {} to {}'.format(q.start_time, q.end_time))\n",
    "print('2nd Quarter: {} to {}'.format((q+1).start_time, (q+1).end_time))\n",
    "print('3rd Quarter: {} to {}'.format((q+2).start_time, (q+2).end_time))\n",
    "print('4th Quarter: {} to {}'.format((q+3).start_time, (q+3).end_time))\n",
    "\n",
    "q_fiscal = pd.Period('2019Q1', freq='Q-MAR')\n",
    "print(\"\\nFor a Fiscal Year...\")\n",
    "print('1st Quarter: {} to {}'.format(q_fiscal.start_time, q_fiscal.end_time))\n",
    "print('2nd Quarter: {} to {}'.format((q_fiscal+1).start_time, (q_fiscal+1).end_time))\n",
    "print('3rd Quarter: {} to {}'.format((q_fiscal+2).start_time, (q_fiscal+2).end_time))\n",
    "print('4th Quarter: {} to {}'.format((q_fiscal+3).start_time, (q_fiscal+3).end_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-01-01 00:00:00')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a monthly frequency range from 2020 to 2021\n",
    "yearly_range_20to21 = pd.period_range('2020','2021',freq='M')\n",
    "\n",
    "yearly_range_20to21 # months of the year\n",
    "yearly_range_20to21[0].start_time # start day of the month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-01-01', '2020-02-01', '2020-03-01', '2020-04-01',\n",
       "               '2020-05-01', '2020-06-01', '2020-07-01', '2020-08-01',\n",
       "               '2020-09-01', '2020-10-01', '2020-11-01', '2020-12-01',\n",
       "               '2021-01-01'],\n",
       "              dtype='datetime64[ns]', freq='MS')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert period index to datetime\n",
    "timestamp_yearly_range_20to21 = yearly_range_20to21.to_timestamp()\n",
    "timestamp_yearly_range_20to21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2020-01', '2020-02', '2020-03', '2020-04', '2020-05', '2020-06',\n",
       "             '2020-07', '2020-08', '2020-09', '2020-10', '2020-11', '2020-12',\n",
       "             '2021-01'],\n",
       "            dtype='period[M]', freq='M')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert datetime to period index\n",
    "yearly_range_20to21 = timestamp_yearly_range_20to21.to_period()\n",
    "yearly_range_20to21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Time Series: Timezones\n",
    "\n",
    "Two types of datetime objects: Naive and Timezone aware\n",
    "\n",
    "- Use `dataframe.tz_localize(tz='<timezone_name>')` to set a timezone and `dataframe.tz_convert(tz='<timezone_name>')` to convert to a different timezone [the list of timezones are given in the `pytz` module]\n",
    "\n",
    "- Can also use `tz=<timezone_name>` in the `pd.date_range()` function to set the timezone in a particular date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Africa/Abidjan',\n",
       " 'Africa/Accra',\n",
       " 'Africa/Addis_Ababa',\n",
       " 'Africa/Algiers',\n",
       " 'Africa/Asmara',\n",
       " 'Africa/Asmera',\n",
       " 'Africa/Bamako',\n",
       " 'Africa/Bangui',\n",
       " 'Africa/Banjul',\n",
       " 'Africa/Bissau',\n",
       " 'Africa/Blantyre',\n",
       " 'Africa/Brazzaville',\n",
       " 'Africa/Bujumbura',\n",
       " 'Africa/Cairo',\n",
       " 'Africa/Casablanca',\n",
       " 'Africa/Ceuta',\n",
       " 'Africa/Conakry',\n",
       " 'Africa/Dakar',\n",
       " 'Africa/Dar_es_Salaam',\n",
       " 'Africa/Djibouti',\n",
       " 'Africa/Douala',\n",
       " 'Africa/El_Aaiun',\n",
       " 'Africa/Freetown',\n",
       " 'Africa/Gaborone',\n",
       " 'Africa/Harare',\n",
       " 'Africa/Johannesburg',\n",
       " 'Africa/Juba',\n",
       " 'Africa/Kampala',\n",
       " 'Africa/Khartoum',\n",
       " 'Africa/Kigali',\n",
       " 'Africa/Kinshasa',\n",
       " 'Africa/Lagos',\n",
       " 'Africa/Libreville',\n",
       " 'Africa/Lome',\n",
       " 'Africa/Luanda',\n",
       " 'Africa/Lubumbashi',\n",
       " 'Africa/Lusaka',\n",
       " 'Africa/Malabo',\n",
       " 'Africa/Maputo',\n",
       " 'Africa/Maseru',\n",
       " 'Africa/Mbabane',\n",
       " 'Africa/Mogadishu',\n",
       " 'Africa/Monrovia',\n",
       " 'Africa/Nairobi',\n",
       " 'Africa/Ndjamena',\n",
       " 'Africa/Niamey',\n",
       " 'Africa/Nouakchott',\n",
       " 'Africa/Ouagadougou',\n",
       " 'Africa/Porto-Novo',\n",
       " 'Africa/Sao_Tome',\n",
       " 'Africa/Timbuktu',\n",
       " 'Africa/Tripoli',\n",
       " 'Africa/Tunis',\n",
       " 'Africa/Windhoek',\n",
       " 'America/Adak',\n",
       " 'America/Anchorage',\n",
       " 'America/Anguilla',\n",
       " 'America/Antigua',\n",
       " 'America/Araguaina',\n",
       " 'America/Argentina/Buenos_Aires',\n",
       " 'America/Argentina/Catamarca',\n",
       " 'America/Argentina/ComodRivadavia',\n",
       " 'America/Argentina/Cordoba',\n",
       " 'America/Argentina/Jujuy',\n",
       " 'America/Argentina/La_Rioja',\n",
       " 'America/Argentina/Mendoza',\n",
       " 'America/Argentina/Rio_Gallegos',\n",
       " 'America/Argentina/Salta',\n",
       " 'America/Argentina/San_Juan',\n",
       " 'America/Argentina/San_Luis',\n",
       " 'America/Argentina/Tucuman',\n",
       " 'America/Argentina/Ushuaia',\n",
       " 'America/Aruba',\n",
       " 'America/Asuncion',\n",
       " 'America/Atikokan',\n",
       " 'America/Atka',\n",
       " 'America/Bahia',\n",
       " 'America/Bahia_Banderas',\n",
       " 'America/Barbados',\n",
       " 'America/Belem',\n",
       " 'America/Belize',\n",
       " 'America/Blanc-Sablon',\n",
       " 'America/Boa_Vista',\n",
       " 'America/Bogota',\n",
       " 'America/Boise',\n",
       " 'America/Buenos_Aires',\n",
       " 'America/Cambridge_Bay',\n",
       " 'America/Campo_Grande',\n",
       " 'America/Cancun',\n",
       " 'America/Caracas',\n",
       " 'America/Catamarca',\n",
       " 'America/Cayenne',\n",
       " 'America/Cayman',\n",
       " 'America/Chicago',\n",
       " 'America/Chihuahua',\n",
       " 'America/Coral_Harbour',\n",
       " 'America/Cordoba',\n",
       " 'America/Costa_Rica',\n",
       " 'America/Creston',\n",
       " 'America/Cuiaba',\n",
       " 'America/Curacao',\n",
       " 'America/Danmarkshavn',\n",
       " 'America/Dawson',\n",
       " 'America/Dawson_Creek',\n",
       " 'America/Denver',\n",
       " 'America/Detroit',\n",
       " 'America/Dominica',\n",
       " 'America/Edmonton',\n",
       " 'America/Eirunepe',\n",
       " 'America/El_Salvador',\n",
       " 'America/Ensenada',\n",
       " 'America/Fort_Nelson',\n",
       " 'America/Fort_Wayne',\n",
       " 'America/Fortaleza',\n",
       " 'America/Glace_Bay',\n",
       " 'America/Godthab',\n",
       " 'America/Goose_Bay',\n",
       " 'America/Grand_Turk',\n",
       " 'America/Grenada',\n",
       " 'America/Guadeloupe',\n",
       " 'America/Guatemala',\n",
       " 'America/Guayaquil',\n",
       " 'America/Guyana',\n",
       " 'America/Halifax',\n",
       " 'America/Havana',\n",
       " 'America/Hermosillo',\n",
       " 'America/Indiana/Indianapolis',\n",
       " 'America/Indiana/Knox',\n",
       " 'America/Indiana/Marengo',\n",
       " 'America/Indiana/Petersburg',\n",
       " 'America/Indiana/Tell_City',\n",
       " 'America/Indiana/Vevay',\n",
       " 'America/Indiana/Vincennes',\n",
       " 'America/Indiana/Winamac',\n",
       " 'America/Indianapolis',\n",
       " 'America/Inuvik',\n",
       " 'America/Iqaluit',\n",
       " 'America/Jamaica',\n",
       " 'America/Jujuy',\n",
       " 'America/Juneau',\n",
       " 'America/Kentucky/Louisville',\n",
       " 'America/Kentucky/Monticello',\n",
       " 'America/Knox_IN',\n",
       " 'America/Kralendijk',\n",
       " 'America/La_Paz',\n",
       " 'America/Lima',\n",
       " 'America/Los_Angeles',\n",
       " 'America/Louisville',\n",
       " 'America/Lower_Princes',\n",
       " 'America/Maceio',\n",
       " 'America/Managua',\n",
       " 'America/Manaus',\n",
       " 'America/Marigot',\n",
       " 'America/Martinique',\n",
       " 'America/Matamoros',\n",
       " 'America/Mazatlan',\n",
       " 'America/Mendoza',\n",
       " 'America/Menominee',\n",
       " 'America/Merida',\n",
       " 'America/Metlakatla',\n",
       " 'America/Mexico_City',\n",
       " 'America/Miquelon',\n",
       " 'America/Moncton',\n",
       " 'America/Monterrey',\n",
       " 'America/Montevideo',\n",
       " 'America/Montreal',\n",
       " 'America/Montserrat',\n",
       " 'America/Nassau',\n",
       " 'America/New_York',\n",
       " 'America/Nipigon',\n",
       " 'America/Nome',\n",
       " 'America/Noronha',\n",
       " 'America/North_Dakota/Beulah',\n",
       " 'America/North_Dakota/Center',\n",
       " 'America/North_Dakota/New_Salem',\n",
       " 'America/Nuuk',\n",
       " 'America/Ojinaga',\n",
       " 'America/Panama',\n",
       " 'America/Pangnirtung',\n",
       " 'America/Paramaribo',\n",
       " 'America/Phoenix',\n",
       " 'America/Port-au-Prince',\n",
       " 'America/Port_of_Spain',\n",
       " 'America/Porto_Acre',\n",
       " 'America/Porto_Velho',\n",
       " 'America/Puerto_Rico',\n",
       " 'America/Punta_Arenas',\n",
       " 'America/Rainy_River',\n",
       " 'America/Rankin_Inlet',\n",
       " 'America/Recife',\n",
       " 'America/Regina',\n",
       " 'America/Resolute',\n",
       " 'America/Rio_Branco',\n",
       " 'America/Rosario',\n",
       " 'America/Santa_Isabel',\n",
       " 'America/Santarem',\n",
       " 'America/Santiago',\n",
       " 'America/Santo_Domingo',\n",
       " 'America/Sao_Paulo',\n",
       " 'America/Scoresbysund',\n",
       " 'America/Shiprock',\n",
       " 'America/Sitka',\n",
       " 'America/St_Barthelemy',\n",
       " 'America/St_Johns',\n",
       " 'America/St_Kitts',\n",
       " 'America/St_Lucia',\n",
       " 'America/St_Thomas',\n",
       " 'America/St_Vincent',\n",
       " 'America/Swift_Current',\n",
       " 'America/Tegucigalpa',\n",
       " 'America/Thule',\n",
       " 'America/Thunder_Bay',\n",
       " 'America/Tijuana',\n",
       " 'America/Toronto',\n",
       " 'America/Tortola',\n",
       " 'America/Vancouver',\n",
       " 'America/Virgin',\n",
       " 'America/Whitehorse',\n",
       " 'America/Winnipeg',\n",
       " 'America/Yakutat',\n",
       " 'America/Yellowknife',\n",
       " 'Antarctica/Casey',\n",
       " 'Antarctica/Davis',\n",
       " 'Antarctica/DumontDUrville',\n",
       " 'Antarctica/Macquarie',\n",
       " 'Antarctica/Mawson',\n",
       " 'Antarctica/McMurdo',\n",
       " 'Antarctica/Palmer',\n",
       " 'Antarctica/Rothera',\n",
       " 'Antarctica/South_Pole',\n",
       " 'Antarctica/Syowa',\n",
       " 'Antarctica/Troll',\n",
       " 'Antarctica/Vostok',\n",
       " 'Arctic/Longyearbyen',\n",
       " 'Asia/Aden',\n",
       " 'Asia/Almaty',\n",
       " 'Asia/Amman',\n",
       " 'Asia/Anadyr',\n",
       " 'Asia/Aqtau',\n",
       " 'Asia/Aqtobe',\n",
       " 'Asia/Ashgabat',\n",
       " 'Asia/Ashkhabad',\n",
       " 'Asia/Atyrau',\n",
       " 'Asia/Baghdad',\n",
       " 'Asia/Bahrain',\n",
       " 'Asia/Baku',\n",
       " 'Asia/Bangkok',\n",
       " 'Asia/Barnaul',\n",
       " 'Asia/Beirut',\n",
       " 'Asia/Bishkek',\n",
       " 'Asia/Brunei',\n",
       " 'Asia/Calcutta',\n",
       " 'Asia/Chita',\n",
       " 'Asia/Choibalsan',\n",
       " 'Asia/Chongqing',\n",
       " 'Asia/Chungking',\n",
       " 'Asia/Colombo',\n",
       " 'Asia/Dacca',\n",
       " 'Asia/Damascus',\n",
       " 'Asia/Dhaka',\n",
       " 'Asia/Dili',\n",
       " 'Asia/Dubai',\n",
       " 'Asia/Dushanbe',\n",
       " 'Asia/Famagusta',\n",
       " 'Asia/Gaza',\n",
       " 'Asia/Harbin',\n",
       " 'Asia/Hebron',\n",
       " 'Asia/Ho_Chi_Minh',\n",
       " 'Asia/Hong_Kong',\n",
       " 'Asia/Hovd',\n",
       " 'Asia/Irkutsk',\n",
       " 'Asia/Istanbul',\n",
       " 'Asia/Jakarta',\n",
       " 'Asia/Jayapura',\n",
       " 'Asia/Jerusalem',\n",
       " 'Asia/Kabul',\n",
       " 'Asia/Kamchatka',\n",
       " 'Asia/Karachi',\n",
       " 'Asia/Kashgar',\n",
       " 'Asia/Kathmandu',\n",
       " 'Asia/Katmandu',\n",
       " 'Asia/Khandyga',\n",
       " 'Asia/Kolkata',\n",
       " 'Asia/Krasnoyarsk',\n",
       " 'Asia/Kuala_Lumpur',\n",
       " 'Asia/Kuching',\n",
       " 'Asia/Kuwait',\n",
       " 'Asia/Macao',\n",
       " 'Asia/Macau',\n",
       " 'Asia/Magadan',\n",
       " 'Asia/Makassar',\n",
       " 'Asia/Manila',\n",
       " 'Asia/Muscat',\n",
       " 'Asia/Nicosia',\n",
       " 'Asia/Novokuznetsk',\n",
       " 'Asia/Novosibirsk',\n",
       " 'Asia/Omsk',\n",
       " 'Asia/Oral',\n",
       " 'Asia/Phnom_Penh',\n",
       " 'Asia/Pontianak',\n",
       " 'Asia/Pyongyang',\n",
       " 'Asia/Qatar',\n",
       " 'Asia/Qostanay',\n",
       " 'Asia/Qyzylorda',\n",
       " 'Asia/Rangoon',\n",
       " 'Asia/Riyadh',\n",
       " 'Asia/Saigon',\n",
       " 'Asia/Sakhalin',\n",
       " 'Asia/Samarkand',\n",
       " 'Asia/Seoul',\n",
       " 'Asia/Shanghai',\n",
       " 'Asia/Singapore',\n",
       " 'Asia/Srednekolymsk',\n",
       " 'Asia/Taipei',\n",
       " 'Asia/Tashkent',\n",
       " 'Asia/Tbilisi',\n",
       " 'Asia/Tehran',\n",
       " 'Asia/Tel_Aviv',\n",
       " 'Asia/Thimbu',\n",
       " 'Asia/Thimphu',\n",
       " 'Asia/Tokyo',\n",
       " 'Asia/Tomsk',\n",
       " 'Asia/Ujung_Pandang',\n",
       " 'Asia/Ulaanbaatar',\n",
       " 'Asia/Ulan_Bator',\n",
       " 'Asia/Urumqi',\n",
       " 'Asia/Ust-Nera',\n",
       " 'Asia/Vientiane',\n",
       " 'Asia/Vladivostok',\n",
       " 'Asia/Yakutsk',\n",
       " 'Asia/Yangon',\n",
       " 'Asia/Yekaterinburg',\n",
       " 'Asia/Yerevan',\n",
       " 'Atlantic/Azores',\n",
       " 'Atlantic/Bermuda',\n",
       " 'Atlantic/Canary',\n",
       " 'Atlantic/Cape_Verde',\n",
       " 'Atlantic/Faeroe',\n",
       " 'Atlantic/Faroe',\n",
       " 'Atlantic/Jan_Mayen',\n",
       " 'Atlantic/Madeira',\n",
       " 'Atlantic/Reykjavik',\n",
       " 'Atlantic/South_Georgia',\n",
       " 'Atlantic/St_Helena',\n",
       " 'Atlantic/Stanley',\n",
       " 'Australia/ACT',\n",
       " 'Australia/Adelaide',\n",
       " 'Australia/Brisbane',\n",
       " 'Australia/Broken_Hill',\n",
       " 'Australia/Canberra',\n",
       " 'Australia/Currie',\n",
       " 'Australia/Darwin',\n",
       " 'Australia/Eucla',\n",
       " 'Australia/Hobart',\n",
       " 'Australia/LHI',\n",
       " 'Australia/Lindeman',\n",
       " 'Australia/Lord_Howe',\n",
       " 'Australia/Melbourne',\n",
       " 'Australia/NSW',\n",
       " 'Australia/North',\n",
       " 'Australia/Perth',\n",
       " 'Australia/Queensland',\n",
       " 'Australia/South',\n",
       " 'Australia/Sydney',\n",
       " 'Australia/Tasmania',\n",
       " 'Australia/Victoria',\n",
       " 'Australia/West',\n",
       " 'Australia/Yancowinna',\n",
       " 'Brazil/Acre',\n",
       " 'Brazil/DeNoronha',\n",
       " 'Brazil/East',\n",
       " 'Brazil/West',\n",
       " 'CET',\n",
       " 'CST6CDT',\n",
       " 'Canada/Atlantic',\n",
       " 'Canada/Central',\n",
       " 'Canada/Eastern',\n",
       " 'Canada/Mountain',\n",
       " 'Canada/Newfoundland',\n",
       " 'Canada/Pacific',\n",
       " 'Canada/Saskatchewan',\n",
       " 'Canada/Yukon',\n",
       " 'Chile/Continental',\n",
       " 'Chile/EasterIsland',\n",
       " 'Cuba',\n",
       " 'EET',\n",
       " 'EST',\n",
       " 'EST5EDT',\n",
       " 'Egypt',\n",
       " 'Eire',\n",
       " 'Etc/GMT',\n",
       " 'Etc/GMT+0',\n",
       " 'Etc/GMT+1',\n",
       " 'Etc/GMT+10',\n",
       " 'Etc/GMT+11',\n",
       " 'Etc/GMT+12',\n",
       " 'Etc/GMT+2',\n",
       " 'Etc/GMT+3',\n",
       " 'Etc/GMT+4',\n",
       " 'Etc/GMT+5',\n",
       " 'Etc/GMT+6',\n",
       " 'Etc/GMT+7',\n",
       " 'Etc/GMT+8',\n",
       " 'Etc/GMT+9',\n",
       " 'Etc/GMT-0',\n",
       " 'Etc/GMT-1',\n",
       " 'Etc/GMT-10',\n",
       " 'Etc/GMT-11',\n",
       " 'Etc/GMT-12',\n",
       " 'Etc/GMT-13',\n",
       " 'Etc/GMT-14',\n",
       " 'Etc/GMT-2',\n",
       " 'Etc/GMT-3',\n",
       " 'Etc/GMT-4',\n",
       " 'Etc/GMT-5',\n",
       " 'Etc/GMT-6',\n",
       " 'Etc/GMT-7',\n",
       " 'Etc/GMT-8',\n",
       " 'Etc/GMT-9',\n",
       " 'Etc/GMT0',\n",
       " 'Etc/Greenwich',\n",
       " 'Etc/UCT',\n",
       " 'Etc/UTC',\n",
       " 'Etc/Universal',\n",
       " 'Etc/Zulu',\n",
       " 'Europe/Amsterdam',\n",
       " 'Europe/Andorra',\n",
       " 'Europe/Astrakhan',\n",
       " 'Europe/Athens',\n",
       " 'Europe/Belfast',\n",
       " 'Europe/Belgrade',\n",
       " 'Europe/Berlin',\n",
       " 'Europe/Bratislava',\n",
       " 'Europe/Brussels',\n",
       " 'Europe/Bucharest',\n",
       " 'Europe/Budapest',\n",
       " 'Europe/Busingen',\n",
       " 'Europe/Chisinau',\n",
       " 'Europe/Copenhagen',\n",
       " 'Europe/Dublin',\n",
       " 'Europe/Gibraltar',\n",
       " 'Europe/Guernsey',\n",
       " 'Europe/Helsinki',\n",
       " 'Europe/Isle_of_Man',\n",
       " 'Europe/Istanbul',\n",
       " 'Europe/Jersey',\n",
       " 'Europe/Kaliningrad',\n",
       " 'Europe/Kiev',\n",
       " 'Europe/Kirov',\n",
       " 'Europe/Lisbon',\n",
       " 'Europe/Ljubljana',\n",
       " 'Europe/London',\n",
       " 'Europe/Luxembourg',\n",
       " 'Europe/Madrid',\n",
       " 'Europe/Malta',\n",
       " 'Europe/Mariehamn',\n",
       " 'Europe/Minsk',\n",
       " 'Europe/Monaco',\n",
       " 'Europe/Moscow',\n",
       " 'Europe/Nicosia',\n",
       " 'Europe/Oslo',\n",
       " 'Europe/Paris',\n",
       " 'Europe/Podgorica',\n",
       " 'Europe/Prague',\n",
       " 'Europe/Riga',\n",
       " 'Europe/Rome',\n",
       " 'Europe/Samara',\n",
       " 'Europe/San_Marino',\n",
       " 'Europe/Sarajevo',\n",
       " 'Europe/Saratov',\n",
       " 'Europe/Simferopol',\n",
       " 'Europe/Skopje',\n",
       " 'Europe/Sofia',\n",
       " 'Europe/Stockholm',\n",
       " 'Europe/Tallinn',\n",
       " 'Europe/Tirane',\n",
       " 'Europe/Tiraspol',\n",
       " 'Europe/Ulyanovsk',\n",
       " 'Europe/Uzhgorod',\n",
       " 'Europe/Vaduz',\n",
       " 'Europe/Vatican',\n",
       " 'Europe/Vienna',\n",
       " 'Europe/Vilnius',\n",
       " 'Europe/Volgograd',\n",
       " 'Europe/Warsaw',\n",
       " 'Europe/Zagreb',\n",
       " 'Europe/Zaporozhye',\n",
       " 'Europe/Zurich',\n",
       " 'GB',\n",
       " 'GB-Eire',\n",
       " 'GMT',\n",
       " 'GMT+0',\n",
       " 'GMT-0',\n",
       " 'GMT0',\n",
       " 'Greenwich',\n",
       " 'HST',\n",
       " 'Hongkong',\n",
       " 'Iceland',\n",
       " 'Indian/Antananarivo',\n",
       " 'Indian/Chagos',\n",
       " 'Indian/Christmas',\n",
       " 'Indian/Cocos',\n",
       " 'Indian/Comoro',\n",
       " 'Indian/Kerguelen',\n",
       " 'Indian/Mahe',\n",
       " 'Indian/Maldives',\n",
       " 'Indian/Mauritius',\n",
       " 'Indian/Mayotte',\n",
       " 'Indian/Reunion',\n",
       " 'Iran',\n",
       " 'Israel',\n",
       " 'Jamaica',\n",
       " 'Japan',\n",
       " 'Kwajalein',\n",
       " 'Libya',\n",
       " 'MET',\n",
       " 'MST',\n",
       " 'MST7MDT',\n",
       " 'Mexico/BajaNorte',\n",
       " 'Mexico/BajaSur',\n",
       " 'Mexico/General',\n",
       " 'NZ',\n",
       " 'NZ-CHAT',\n",
       " 'Navajo',\n",
       " 'PRC',\n",
       " 'PST8PDT',\n",
       " 'Pacific/Apia',\n",
       " 'Pacific/Auckland',\n",
       " 'Pacific/Bougainville',\n",
       " 'Pacific/Chatham',\n",
       " 'Pacific/Chuuk',\n",
       " 'Pacific/Easter',\n",
       " 'Pacific/Efate',\n",
       " 'Pacific/Enderbury',\n",
       " 'Pacific/Fakaofo',\n",
       " 'Pacific/Fiji',\n",
       " 'Pacific/Funafuti',\n",
       " 'Pacific/Galapagos',\n",
       " 'Pacific/Gambier',\n",
       " 'Pacific/Guadalcanal',\n",
       " 'Pacific/Guam',\n",
       " 'Pacific/Honolulu',\n",
       " 'Pacific/Johnston',\n",
       " 'Pacific/Kiritimati',\n",
       " 'Pacific/Kosrae',\n",
       " 'Pacific/Kwajalein',\n",
       " 'Pacific/Majuro',\n",
       " 'Pacific/Marquesas',\n",
       " 'Pacific/Midway',\n",
       " 'Pacific/Nauru',\n",
       " 'Pacific/Niue',\n",
       " 'Pacific/Norfolk',\n",
       " 'Pacific/Noumea',\n",
       " 'Pacific/Pago_Pago',\n",
       " 'Pacific/Palau',\n",
       " 'Pacific/Pitcairn',\n",
       " 'Pacific/Pohnpei',\n",
       " 'Pacific/Ponape',\n",
       " 'Pacific/Port_Moresby',\n",
       " 'Pacific/Rarotonga',\n",
       " 'Pacific/Saipan',\n",
       " 'Pacific/Samoa',\n",
       " 'Pacific/Tahiti',\n",
       " 'Pacific/Tarawa',\n",
       " 'Pacific/Tongatapu',\n",
       " 'Pacific/Truk',\n",
       " 'Pacific/Wake',\n",
       " 'Pacific/Wallis',\n",
       " 'Pacific/Yap',\n",
       " 'Poland',\n",
       " 'Portugal',\n",
       " 'ROC',\n",
       " 'ROK',\n",
       " 'Singapore',\n",
       " 'Turkey',\n",
       " 'UCT',\n",
       " 'US/Alaska',\n",
       " 'US/Aleutian',\n",
       " 'US/Arizona',\n",
       " 'US/Central',\n",
       " 'US/East-Indiana',\n",
       " 'US/Eastern',\n",
       " 'US/Hawaii',\n",
       " 'US/Indiana-Starke',\n",
       " 'US/Michigan',\n",
       " 'US/Mountain',\n",
       " 'US/Pacific',\n",
       " 'US/Samoa',\n",
       " 'UTC',\n",
       " 'Universal',\n",
       " 'W-SU',\n",
       " 'WET',\n",
       " 'Zulu']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of all timezones\n",
    "from pytz import all_timezones\n",
    "all_timezones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-01-01 00:00:00-05:00', '2020-02-01 00:00:00-05:00',\n",
       "               '2020-03-01 00:00:00-05:00', '2020-04-01 00:00:00-04:00',\n",
       "               '2020-05-01 00:00:00-04:00', '2020-06-01 00:00:00-04:00',\n",
       "               '2020-07-01 00:00:00-04:00', '2020-08-01 00:00:00-04:00',\n",
       "               '2020-09-01 00:00:00-04:00', '2020-10-01 00:00:00-04:00',\n",
       "               '2020-11-01 00:00:00-04:00', '2020-12-01 00:00:00-05:00',\n",
       "               '2021-01-01 00:00:00-05:00'],\n",
       "              dtype='datetime64[ns, US/Eastern]', freq=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting a timezone\n",
    "timestamp_yearly_range_20to21 = timestamp_yearly_range_20to21.tz_localize(tz='US/Eastern')\n",
    "timestamp_yearly_range_20to21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-01-01 10:30:00+05:30', '2020-02-01 10:30:00+05:30',\n",
       "               '2020-03-01 10:30:00+05:30', '2020-04-01 09:30:00+05:30',\n",
       "               '2020-05-01 09:30:00+05:30', '2020-06-01 09:30:00+05:30',\n",
       "               '2020-07-01 09:30:00+05:30', '2020-08-01 09:30:00+05:30',\n",
       "               '2020-09-01 09:30:00+05:30', '2020-10-01 09:30:00+05:30',\n",
       "               '2020-11-01 09:30:00+05:30', '2020-12-01 10:30:00+05:30',\n",
       "               '2021-01-01 10:30:00+05:30'],\n",
       "              dtype='datetime64[ns, Asia/Calcutta]', freq=None)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to a different timezone\n",
    "india_timestamp_yearly_range_20to21 = timestamp_yearly_range_20to21.tz_convert(tz='Asia/Calcutta')\n",
    "india_timestamp_yearly_range_20to21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Time Series: Shifting and Lagging\n",
    "\n",
    "- Use `dataframe.shift(num)` to shift the values in a dataframe by a certain num of rows.\n",
    "    - Enter num > 0, for shifting ahead\n",
    "    - Enter num < 0, for shifting back\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"google_Jan2022.csv\"\n",
    "google_stock_df = pd.read_csv(file_name, header=1, parse_dates=[\"Date\"], index_col=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>5day_return%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>2901.49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04</th>\n",
       "      <td>2888.33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-05</th>\n",
       "      <td>2753.07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-06</th>\n",
       "      <td>2751.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-07</th>\n",
       "      <td>2740.09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-10</th>\n",
       "      <td>2771.48</td>\n",
       "      <td>-4.480801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>2800.35</td>\n",
       "      <td>-3.046051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-12</th>\n",
       "      <td>2832.96</td>\n",
       "      <td>2.901851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-13</th>\n",
       "      <td>2782.62</td>\n",
       "      <td>1.148665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14</th>\n",
       "      <td>2795.73</td>\n",
       "      <td>2.030590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-18</th>\n",
       "      <td>2725.81</td>\n",
       "      <td>-1.647856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-19</th>\n",
       "      <td>2713.04</td>\n",
       "      <td>-3.117825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-20</th>\n",
       "      <td>2670.13</td>\n",
       "      <td>-5.747699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-21</th>\n",
       "      <td>2601.84</td>\n",
       "      <td>-6.496755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-24</th>\n",
       "      <td>2607.44</td>\n",
       "      <td>-6.734914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-25</th>\n",
       "      <td>2534.71</td>\n",
       "      <td>-7.010760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-26</th>\n",
       "      <td>2584.80</td>\n",
       "      <td>-4.726801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-27</th>\n",
       "      <td>2582.42</td>\n",
       "      <td>-3.284859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-28</th>\n",
       "      <td>2665.79</td>\n",
       "      <td>2.457876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Close  5day_return%\n",
       "Date                             \n",
       "2022-01-03  2901.49           NaN\n",
       "2022-01-04  2888.33           NaN\n",
       "2022-01-05  2753.07           NaN\n",
       "2022-01-06  2751.02           NaN\n",
       "2022-01-07  2740.09           NaN\n",
       "2022-01-10  2771.48     -4.480801\n",
       "2022-01-11  2800.35     -3.046051\n",
       "2022-01-12  2832.96      2.901851\n",
       "2022-01-13  2782.62      1.148665\n",
       "2022-01-14  2795.73      2.030590\n",
       "2022-01-18  2725.81     -1.647856\n",
       "2022-01-19  2713.04     -3.117825\n",
       "2022-01-20  2670.13     -5.747699\n",
       "2022-01-21  2601.84     -6.496755\n",
       "2022-01-24  2607.44     -6.734914\n",
       "2022-01-25  2534.71     -7.010760\n",
       "2022-01-26  2584.80     -4.726801\n",
       "2022-01-27  2582.42     -3.284859\n",
       "2022-01-28  2665.79      2.457876"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showcase previous day closing price\n",
    "google_stock_df['prev_day_close'] = google_stock_df['Close'].shift(1)\n",
    "google_stock_df[['Close','prev_day_close']]\n",
    "\n",
    "# 1 day absolute price change\n",
    "google_stock_df['prev_day_change'] = google_stock_df['Close'] - google_stock_df['prev_day_close']\n",
    "google_stock_df[['Close','prev_day_close','prev_day_change']]\n",
    "\n",
    "# 5 day price change %\n",
    "google_stock_df['5day_return%'] = (google_stock_df['Close'] - google_stock_df['Close'].shift(5))*100/(google_stock_df['Close'].shift(5))\n",
    "google_stock_df[['Close','5day_return%']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('anaconda3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43b2c1e240e0c2879b782cdfd471e8eeaf7564f6fe4dbe35ada4711a315e5a9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
